{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast_ml_ws.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCpS7mKSKtV4",
        "colab_type": "text"
      },
      "source": [
        "Per prima cosa vi ricordo che questo programma e' sperimentale. Nemmeno in alfa o beta status. E' una prova di concetto sperimentale e il suo uso potrebbe costarvi soldi o, peggio farvi perdere dati. \n",
        "\n",
        "Ad ogni modo il (c) e' di Giovambattista Vieri  e, la licenza e' quella che volete (WTF o mit o come vi pare)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoR1xmsAgy_4",
        "colab_type": "text"
      },
      "source": [
        "Per prima cosa e' necessario fare il download del file dati. https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset/downloads/5-celebrity-faces-dataset.zip/3\n",
        "\n",
        "Lo troverete sul vostro computer. Si chiama 5-celebrity-faces-dataset.zip e, e' necessario scompattarlo. Al suo interno troverete un file zip che dovrete poi caricare. Si chiama data.zip. \n",
        "\n",
        "Ora procediamo. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teEeu2KhKl5I",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxKcqmpyiGke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW1_azuziMY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import os \n",
        "os.mkdir('data')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-XANwxKFrSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('models')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJYZpkNOoWjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp data.zip data\n",
        "!cd data\n",
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjSShE5logHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!ls -l data \n",
        "!mv train data\n",
        "!mv val data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGYWtguBokYc",
        "colab_type": "text"
      },
      "source": [
        "Presumibilmente ora i dati sono stati caricati. \n",
        "Passiamo all'ambiente\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mvExMuTC-6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -la data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7PDCGJ4ovyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy matplotlib\n",
        "!pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOtJ6LFypXQ0",
        "colab_type": "text"
      },
      "source": [
        "finalmente abbiam finito i convenevoli \n",
        "\n",
        "passiamo al codice: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvboOIo8DXhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWYOxeYWDZ0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_cat=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRlhcOUPDePZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'validation':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTk9f3QRDkAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_datasets = {\n",
        "    'train':\n",
        "    datasets.ImageFolder('data/train', data_transforms['train']),\n",
        "    'validation':\n",
        "    datasets.ImageFolder('data/val', data_transforms['validation'])\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    'train':\n",
        "    torch.utils.data.DataLoader(image_datasets['train'],\n",
        "                                batch_size=15,\n",
        "                                shuffle=True, num_workers=4),\n",
        "    'validation':\n",
        "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
        "                                batch_size=15,\n",
        "                                shuffle=False, num_workers=4)\n",
        "}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB00YlLiDuPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\") # I want to be able to repeat ... \n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, num_of_cat)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD32EhpMDuS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=6):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.detach() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(image_datasets[phase])\n",
        "            epoch_acc = running_corrects.float() / len(image_datasets[phase])\n",
        "\n",
        "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
        "                                                        epoch_loss.item(),\n",
        "                                                        epoch_acc.item()))\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clSlbbUJEHoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_trained = train_model(model, criterion, optimizer, num_epochs=6)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFiRMO_2F0bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_trained.state_dict(), 'models/weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDygO0f8EJgL",
        "colab_type": "text"
      },
      "source": [
        "ora il modello e' allenato, e, salvato... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpmFDjc5F3s0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "validation_img_paths = [\"data/val/elton_john/httpcdnlyricssongonlyricsnetwpcontentuploadsEltonJohnDiscographyCDreleasesjpg.jpg\",\n",
        "                        \"data/val/madonna/httpecximagesamazoncomimagesIfmaBKWLACULSRjpg.jpg\",\n",
        "                        \"data/val/madonna/httpcdncdnjustjaredcomwpcontentuploadsheadlinesmadonnatalksparisattackstearsjpg.jpg\",\n",
        "                        \"data/val/jerry_seinfeld/httpblognjcomentertainmentimpactcelebritiesmediumjerrybjpg.jpg\",\n",
        "                        \"data/val/mindy_kaling/httpcdnpastemagazinecomwwwarticlesmindyprojectjpg.jpg\",\n",
        "                        \"data/val/ben_afflek/httpabsolumentgratuitfreefrimagesbenaffleckjpg.jpg\"]\n",
        "img_list = [Image.open(img_path) for img_path in validation_img_paths]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-lNRX0UGFme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list = [Image.open(img_path) for img_path in validation_img_paths]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISA0DREAGGua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_batch = torch.stack([data_transforms['validation'](img).to(device) for img in img_list])\n",
        "\n",
        "pred_logits_tensor = model(validation_batch)\n",
        "pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSL5NjobGLMW",
        "colab_type": "text"
      },
      "source": [
        "predizione effettuata...\n",
        "VEDIAMO I RISULTATI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVHYL6ImGTjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(1, len(img_list), figsize=(15, 5))\n",
        "#fig, axs = plt.subplots(1, len(img_list),figsize=(20,5))\n",
        "\n",
        "\n",
        "for i, img in enumerate(img_list):\n",
        "    ax = axs[i]\n",
        "    ax.axis('off')\n",
        "    ax.set_title(\"{:.0f}% BA, {:.0f}% EJ,\\n {:.0f}% JS, {:.0f}% M, {:.0f}% MK\".format(100*pred_probs[i,0], 100*pred_probs[i,1],100*pred_probs[i,2],100*pred_probs[i,3],100*pred_probs[i,4]))\n",
        "    ax.imshow(img)\n",
        "fig.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}